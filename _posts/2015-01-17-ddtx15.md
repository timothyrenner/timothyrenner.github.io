---
title: "#ddtx15"
tags: notebook twitter
categories: data
layout: post
---

Last weekend I attended Data Day Texas here in Austin and it was awesome.
I decided it would be fun to look at the tweets for the day, hashtagged (real
verb) with `ddtx15`.
These tweets were scraped around 9:00 PM on Jan 10, 2015 using the REST api.

###tl;dr
Bar plots.

I originally did this work with an IPython Notebook.
I've used Jekyll's templating engine to modify it so that the code is hidden.
Anywhere you see a panel with the word "Code", you can click it and show the code.
Try it out on the panel below, which performs the imports and sets some plot configuration.

{% include code-panel-open.html panel_id="one" %}
{% highlight python %}

import json
import tweet_utils as tu
import matplotlib.pyplot as plt
import pandas as pd

%matplotlib inline
plt.style.use('ggplot') # ggplot isn't the default style.

{% endhighlight %}
{% include code-panel-close.html %}

This dataset (sort of) is available [here](https://s3-us-
west-2.amazonaws.com/timothyrenner.github.io.datasets/ddtx_tweet_ids.json).
There will be more on how to obtain _real_ the dataset at the end.

{% include code-panel-open.html panel_id="two" %}
{% highlight python %}

tweets = json.loads(open("ddtx_tweets.json").read())
print("Number of tweets: %d" % len(tweets))

{% endhighlight %}
{% include code-panel-close.html %}        

    Number of tweets: 675


Let's start by looking at who tweeted the most.
Pandas makes it pretty easy.

{% include code-panel-open.html panel_id="three" %}
{% highlight python %}
tweeter_freqs = pd.DataFrame(pd.Series(
    [t['user']['screen_name'] for t in tweets]).value_counts(),
        columns=["freqs"]).\
    sort(columns="freqs", ascending=False)
        
# Plot the top 10, but reverse the order to put the most frequent ones at the top.
tweeter_freqs[10::-1].plot(kind="barh", 
    title="Most Frequent Tweeters",
    legend=False, 
    color="m")
    
plt.show()

{% endhighlight %}
{% include code-panel-close.html %}
![png]({{ site.url }}/images/ddtx15/ddtx15_5_0.png)


I'm a little surprised strataconf is the top tweeter.
Let's print the tweets and see what's up.

{% include code-panel-open.html panel_id="four" %}
{% highlight python %}

for tweet in [t for t in tweets if t['user']['screen_name']][:10]:
    print(tweet['text'])
    print

{% endhighlight %}
{% include code-panel-close.html %}

    Favorite new friend from #ddtx15. Love this girl! @inataliaking http://t.co/cTb7sR7aUP
    
    RT @wesmckinn: Slides from my #ddtx15 talk about opportunities and challenges for Python and big data http://t.co/lzaOeDyVVo #pydata
    
    RT @wesmckinn: Slides from my #ddtx15 talk about opportunities and challenges for Python and big data http://t.co/lzaOeDyVVo #pydata
    
    RT @wesmckinn: Slides from my #ddtx15 talk about opportunities and challenges for Python and big data http://t.co/lzaOeDyVVo #pydata
    
    RT @jltrem: Listening to @mipsytipsy #uncensored talk on db upgrade horrors #ddtx15 http://t.co/Jw82NNK1zX
    
    Had a great day in #Austin for #ddtx15 .... Awesome sessions
    
    RT @posco: 1: Yeah, but log(N) is actually pretty large.
    2: Well, no it's not.
    #logNgate #ddtx15
    
    RT @mlehmann: For those that are learning @MongoDB and doing upgrade on their own, learn from @mipsytipsy slides of her awesome presentatioâ€¦
    
    For those that are learning @MongoDB and doing upgrade on their own, learn from @mipsytipsy slides of her awesome presentation at #ddtx15
    
    RT @wesmckinn: Slides from my #ddtx15 talk about opportunities and challenges for Python and big data http://t.co/lzaOeDyVVo #pydata
    


So, lots of retweets.
We should count the ones that aren't retweets.

{% include code-panel-open.html panel_id="five" %}
{% highlight python %}

# Retweeted tweets have a `retweeted_status` field.
non_rt_tweets = [t for t in tweets if 'retweeted_status' not in t]

print("Number of non-retweeted tweets: %d"%len(non_rt_tweets))

{% endhighlight %}
{% include code-panel-close.html %}

    Number of non-retweeted tweets: 299


Now we can look at the tweeter frequencies without the retweets and see what we
get.


{% include code-panel-open.html panel_id="six" %}
{% highlight python %}

non_retweeting_tweeter_freqs =\
    pd.DataFrame(pd.Series(
    [t['user']['screen_name'] for t in non_rt_tweets]).value_counts(),
        columns=["freqs"]).\
    sort(columns="freqs", ascending=False)
    
non_retweeting_tweeter_freqs[10::-1].plot(
    kind="barh", 
    legend=False, 
    color="m", 
    title="Most Frequent Tweeters")
    
plt.show()

{% endhighlight %}
{% include code-panel-close.html %}


![png]({{ site.url }}/images/ddtx15/ddtx15_11_0.png)


Now things look a little more balanced.
Interesting that none of them were speakers.
I guess they were busy...

So which programming language was the hottest?
As far as the talks go, scala was the definite star of the show.
Let's see if the tweeting audience agreed.

We're going to count the number of tweets containing each of the following
languages (these are the languages I heard mentioned by name at the talks - and
yes, I'm aware SQL is not technically a programming language):

- Python
- Java
- Scala
- R
- Clojure (I swear I heard it in the keynote. Maybe.)
- SQL

First the next needs to be preprocessed: remove leading or trailing puncutation,
make lower case.
I've got a function in my `tweet_utils` module (loaded as `tu`) that does just
this.
It also removes URLs, hashtags, symbols, mentions, and media.
I'll be sure to add the hashtags to the search criteria so we don't miss any
`#clojure` s.

Here's what the `get_text_sanitized` function does.

{% include code-panel-open.html panel_id="seven" %}
{% highlight python %}

print("Raw text: " + tweets[53]['text'])
print
print("Sanitized text: " + tu.get_text_sanitized(tweets[53]))

{% endhighlight %}
{% include code-panel-close.html %}

    Raw text: Think I won the stuff they didn't want to carry home ;-) @strataconf: Final prize goes to @grayabbott. #ddtx15 http://t.co/jRGSfWVAAr
    
    Sanitized text: think i won the stuff they didn't want to carry home final prize goes to


It's not perfect, but it will do fine here since we're not doing anything nlp
related with it.
I've posted it as a
[gist](https://gist.github.com/timothyrenner/dd487b9fd8081530509c#file-
tweet_utils-py) for those following the code.

Alright, let's make a plot.

{% include code-panel-open.html panel_id="eight" %}
{% highlight python %}

programming_languages = {"python", "java", "scala", "r", "clojure", "sql"}

# Sanitize the text first.
for tweet in tweets:
    tweet['sanitized_text'] = tu.get_text_sanitized(tweet)

# What follows is brutally inefficient. I promise I didn't notice when I ran it.
    
language_list = [] # Put the languages in a flat list.
for tweet in tweets:
    # Add any matching hashtags to the list.
    hashtags = [h.lower() for h in tu.get_hashtags(tweet)]
    for h in hashtags:
        if h in programming_languages:
            language_list += [h]
    
    # Scan the text for additional hashtags.
    for word in tweet['sanitized_text'].split():
        if word in programming_languages:
            language_list += [word]

# Do the counting and make the plot.
languages = pd.DataFrame(pd.Series(
    language_list).value_counts(), 
    columns=["freqs"]).\
    sort(columns="freqs", ascending=False)
    
languages[::-1].plot(
    kind='barh', 
    color='m', 
    title="Language Frequencies", 
    legend=False)
    
plt.show()

{% endhighlight %}
{% include code-panel-close.html %}

![png]({{ site.url }}/images/ddtx15/ddtx15_16_0.png)


I'm pretty surprised about this: my money was on scala.
The languages that didn't appear weren't mentioned.

Let's see what this is without the retweet effect.

{% include code-panel-open.html panel_id="nine" %}
{% highlight python %}

non_rt_language_list = []
for tweet in non_rt_tweets:
    hashtags = [h.lower() for h in tu.get_hashtags(tweet)]
    for h in hashtags:
        if h in programming_languages:
            non_rt_language_list += [h]
    
    for word in tweet['sanitized_text'].split():
        if word in programming_languages:
            non_rt_language_list += [word]

non_rt_languages = pd.DataFrame(pd.Series(
    non_rt_language_list).value_counts(), columns=["freqs"]).\
    sort(columns="freqs", ascending=False)
    
non_rt_languages[::-1].plot(
    kind='barh', 
    title="Language Frequencies", 
    color="m", 
    legend=False)
    
plt.show()

{% endhighlight %}
{% include code-panel-close.html %}


![png]({{ site.url }}/images/ddtx15/ddtx15_18_0.png)


...and it's still python, in roughly the same proportion to scala.
Another fun fact: nobody retweeted Java.

> "Alright, we're getting in to some hardcore data science now.
> We are counting some shit."
>
>  \- [@posco](https://www.twitter.com/posco)

Now we'll switch gears a little bit and look at mentions.
Let's grab the mentions and count some shit.

{% include code-panel-open.html panel_id="ten" %}
{% highlight python %}

all_mentions = [u.lower() for t in tweets for u in tu.get_user_mentions(t)]

print("All mentions: %d" % len(all_mentions))
print("Unique mentions: %d" % len(set(all_mentions)))

{% endhighlight %}
{% include code-panel-close.html %}

    All mentions: 1092
    Unique mentions: 115


... and plot them up with a data frame.

{% include code-panel-open.html panel_id="eleven" %}
{% highlight python %}

mention_freqs = pd.DataFrame(pd.Series(
    all_mentions).value_counts(), columns=["freqs"]).\
    sort(columns="freqs", ascending=False)
    
mention_freqs[15::-1].plot(
    kind="barh", 
    color="m", 
    title="Mention Frequencies", 
    legend=False)
    
plt.show()

{% endhighlight %}
{% include code-panel-close.html %}

![png]({{ site.url }}/images/ddtx15/ddtx15_24_0.png)


Not surprisingly, [@datadaytexas](http://www.twitter.com/datadaytexas) is the
clear frontrunner.
Other interesting tidbits are that there are a lot of speakers.
Taylor Goetz ([@ptgoetz](http://www.twitter.com/ptgoetz)) actually used Twitter
for his wicked cool Arduino/Kafka/Storm demo, so his being up there isn't too
surprising.
Wes McKinney ([@wesmckinn](http://www.twitter.com/wesmckinn), author of the
`pandas` package) is up there too, which isn't shocking given the popularity of
python pointed out above.
It's pretty neat (to me anyway) to see slideshare on the list - I'd guess that's
where most of the talks ended up after they were given.
Or perhaps one really popular talk.

Let's take a look at the non-retweeted mentions.

{% include code-panel-open.html panel_id="twelve" %}
{% highlight python %}

all_mentions_non_rt = [u.lower() for t in non_rt_tweets for u in tu.get_user_mentions(t)]

print("All non-rt mentions: %d"%len(all_mentions_non_rt))
print("Unique mentions: %d"%len(set(all_mentions_non_rt)))

{% endhighlight %}
{% include code-panel-close.html %}

    All non-rt mentions: 329
    Unique mentions: 85


When you think about it, it's pretty strange that there are fewer _unique_
mentions when the retweets are taken out.
I think it means that some of the retweets got the `#ddtx15` hashtag added to
the original tweet.

{% include code-panel-open.html panel_id="thirteen" %}
{% highlight python %}

non_rt_mention_freqs = pd.DataFrame(pd.Series(
    all_mentions_non_rt).value_counts(), columns=["freqs"]).\
    sort(columns="freqs", ascending=False)
    
non_rt_mention_freqs[15::-1].plot(
    kind="barh", 
    title="Mention Frequencies", 
    color="m", 
    legend=False)
    
plt.show()

{% endhighlight %}
{% include code-panel-close.html %}

![png]({{ site.url }}/images/ddtx15/ddtx15_29_0.png)


Well, we lost slideshare - it was probably just a few tweets that got retweeted
a whole bunch.


As part of this study I painstakingly assembled a map of user handles to the
speakers.
You can check them out in the code below.
I pulled these off the [Data Day Texas](http://datadaytexas.com/) website, so if
there's anyone missing that's why.


{% include code-panel-open.html panel_id="fourteen" %}
{% highlight python %}

speaker_handles = {"pacoid": "Paco Nathan",
                   "nathanmarz": "Nathan Marz",
                   "boudicca": "Lisa Green",
                   "mark_grover": "Mark Grover",
                   "deanwampler": "Dean Wampler",
                   "ptgoetz": "Taylor Goetz",
                   "harisr1234": "Hari Shreedharan",
                   "mjkirk": "Matthew Kirk",
                   "rhatr": "Roman Shaposhnik",
                   "ted_dunning": "Ted Dunning",
                   "caseysoftware": "Keith Casey",
                   "posco": "Oscar Boykin",
                   "sandysifting": "Sandy Ryza",
                   "esammer": "Eric Sammer",
                   "wesmckinn":"Wes McKinney",                   
                   "b0rk":"Julia Evans", 
                   "mrchrisjohnson":"Chris Johnson", 
                   "mipsytipsy": "Charity Majors",
                   "astrobiased": "Eli Bressert"}            
{% endhighlight %}
{% include code-panel-close.html %}

I'll just make the same bar plots as we've been making. #tired


{% include code-panel-open.html panel_id="fifteen" %}
{% highlight python %}

speaker_mentions = [m for m in all_mentions if m in speaker_handles.keys()]

speaker_mention_freqs = pd.DataFrame(pd.Series(
    speaker_mentions).value_counts(), columns=["freqs"]).\
    sort(columns="freqs", ascending=False)
    
speaker_mention_freqs.index = [speaker_handles[s] for s in speaker_mention_freqs.index]
    
speaker_mention_freqs[::-1].plot(
        kind="barh", 
        title="Speaker Mention Frequencies", 
        color="m", 
        legend=False)
        
plt.show()

{% endhighlight %}
{% include code-panel-close.html %}

![png]({{ site.url }}/images/ddtx15/ddtx15_34_0.png)


... and without the retweets for good measure.


{% include code-panel-open.html panel_id="sixteen" %}
{% highlight python %}

speaker_mentions_non_rt = [m for m in all_mentions_non_rt if m in speaker_handles.keys()]
    
non_rt_speaker_mention_freqs = pd.DataFrame(pd.Series(
    speaker_mentions_non_rt).value_counts(), 
        columns=["freqs"]).\
    sort(columns="freqs", ascending=False)
    
non_rt_speaker_mention_freqs.index = [speaker_handles[s]
    for s in non_rt_speaker_mention_freqs.index]

non_rt_speaker_mention_freqs[::-1].plot(
    kind="barh", 
    title="Speaker Mention Frequencies", 
    color="m", 
    legend=False)

plt.show()

{% endhighlight %}
{% include code-panel-close.html %}

![png]({{ site.url }}/images/ddtx15/ddtx15_36_0.png)


Why the Hell Aren't There Tweets in the Dataset?
------------------------------------------------

So here's the deal about the dataset.
The link's [here](https://s3-us-
west-2.amazonaws.com/timothyrenner.github.io.datasets/ddtx_tweet_ids.json) if
you don't have it (it's very small).

If you download the file you'll notice that it's just a JSON list of ID strings.
This is because the Twitter API terms of service only allows data to be
distributed as tweet or user IDs.
You can recreate the dataset by issuing a `GET` command to the `statuses/lookup`
endpoint of the Twitter API ([details
here](https://dev.twitter.com/rest/reference/get/statuses/lookup)).
The rate limit is 180 per 15 minute window, and you can grab up to 100 tweets at
a time, so it should be easy to reconstruct this dataset from the IDs in one
session window.
You will need your own set of API keys.

I'm currently working on some toolage to do this, but it isn't ready for the
light of day.
Check back at the blog or my [Github](https://www.github.com/timothyrenner) in a
month or so and hopefully it will be up.

Have You Posted the IPython Notebook Too?
-----------------------------------------

Hell yeah, grab it [here]({{ site.url }}/notebooks/).
You'll need the `tweet_utils`
[gist](https://gist.github.com/timothyrenner/dd487b9fd8081530509c#file-
tweet_utils-py), as well as matplotlib and pandas.
`tweet_utils` also requires the NLTK, but you can delete the function that uses
it (`get_text_normalized`) to remove the dependency.
It's a pretty handy function for preparing text for machine learning feature
vectors, but it isn't necessary here.
There's some other nifty stuff in there like getting the date as a `datetime`
object - just stuff I've found handy to have.
