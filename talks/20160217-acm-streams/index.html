<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="An Ad Venture with Storm, Spark, and Kafka">
  <title>What's Tough About Streams</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../reveal.js/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../reveal.js/css/theme/simple.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? '../reveal.js/css/print/pdf.css' : '../reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
  <h1 class="title"><strong>What's Tough About Streams</strong></h1>
  <h2 class="author">An Ad Venture with Storm, Spark, and Kafka</h2>
  <h3 class="date">Tim Renner, <em>Intersys</em></h3>
</section>

<section id="about-me" class="slide level1">
<h1>About Me</h1>
<style>
.reveal li {line-height: 1.0; margin-bottom: 10px; margin-top: 10px}
.reveal h1 { font-size: 1.5em; } 
.reveal h2 { font-size: 1.0em; }
.reveal code { background-color: #ffffe5 }
.reveal section img { border:none; box-shadow: none}
.reveal section social-link {font-size: 20px; 
                                  font-weight: bold}
.reveal site-link {font-size: 25px; font-weight: bold} 
</style>
<p><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css"></p>
<h3 id="data-scientist-data-engineer-intersys">Data Scientist / Data Engineer @ Intersys</h3>
<p><br> <a href="http://timothyrenner.github.io" class=site-link>timothyrenner.github.io</a> <br><br> <i class="fa fa-2x fa-github"></i>  <a href="http://www.github.com/timothyrenner" class=social-link style="vertical-align: 30%">github.com/timothyrenner</a>    <i class="fa fa-2x fa-twitter"></i>  <a href="http://www.twitter.com/timothyrenner" class=social-link style="vertical-align: 30%"><span class="citation" data-cites="timothyrenner">@timothyrenner</span></a></p>
</section>
<section id="section" class="slide level1">
<h1><img src="images/intersys-logo-horizontal.png" /></h1>
<p>Consulting + Recruiting <br><br></p>
<p><strong>Big Data and Analytics</strong>, Application Development, Data Warehousing</p>
<p><br> <i class="fa fa-2x fa-twitter"></i>  <a href="http://www.twitter.com/intersysconsult" class=social-link style="vertical-align: 30%"><span class="citation" data-cites="intersysconsult">@intersysconsult</span></a>    <a href="http://www.intersysconsulting.com" class=site-link style="vertical-align: 30%">intersysconsulting.com</a></p>
</section>
<section id="the-scenario" class="slide level1">
<h1>The Scenario</h1>
<p>Suppose we want to compute the clickthrough of an online ad campaign.</p>
<ul>
<li>Running a sophisticated live optimization scheme</li>
<li>Run a live A/B test and want to hack some p-values</li>
<li>Your executive was told to &quot;get this in real-time&quot;</li>
</ul>
</section>
<section id="clickthrough" class="slide level1">
<h1>Clickthrough</h1>
<p><br> <br> <br> <span class="math display">\[    
 c = \frac{n_{\text{clicks}}}   
 {n_{\text{impressions}}}
\]</span></p>
</section>
<section id="batch-solution" class="slide level1">
<h1>Batch Solution</h1>
<figure>
<img src="images/ad_batch_solution.png" />
</figure>
</section>
<section id="batch-solution-1" class="slide level1">
<h1>Batch Solution</h1>
<ul>
<li>Data is bounded</li>
<li>Data is static</li>
<li>Complete view of the data</li>
</ul>
<div class="fragment">
<p style="border: solid">
In short, all of the things that make it different from streaming data.
</p>
</div>
</section>
<section id="stream-processing" class="slide level1">
<h1>Stream Processing</h1>
<p><br> <img src="images/storm_logo.png" width=250 height=100 class="logo" style="border:none; box-shadow:none">           <img src="images/spark_streaming_logo.png" height=100 width=150 style="border:none; box-shadow:none"></p>
<p><img src="images/flink_logo.png" width=250 height=100 style="border:none; box-shadow: none">          <img src="images/samza_logo.jpg" width=250 height=100 style="border:none; box-shadow: none"></p>
</section>
<section id="spark-streaming" class="slide level1">
<h1>Spark Streaming</h1>
<ul>
<li>Uses &quot;microbatches&quot; on a continuous stream of data</li>
<li>Each batch is an RDD, allowing code reuse</li>
</ul>
<div class="fragment">
<figure>
<img src="images/spark_streaming_rdd.png" />
</figure>
</div>
</section>
<section id="spark-streaming-solution" class="slide level1">
<h1>Spark Streaming Solution</h1>
<figure>
<img src="images/spark_streaming_naive.png" />
</figure>
<p>Basically the same as batch, but does it really solve the problem?</p>
</section>
<section id="streaming-join" class="slide level1">
<h1>Streaming Join</h1>
<ul>
<li>Microbatch length has to be shorter than time to click.</li>
<li>Lots of &quot;boundary loss&quot; at microbatch edges.</li>
<li>Assumes microbatches are ordered.</li>
</ul>
<div class="fragment">
<hr>
<h3 id="dont-cross-the-streams"><strong>Don't Cross the Streams</strong></h3>
<figure>
<img src="images/dont_cross_the_streams.jpg" />
</figure>
</div>
</section>
<section id="windows" class="slide level1">
<h1>Windows</h1>
<ul>
<li>Windows merge RDDs from the DStream</li>
<li>Rolls old data out as new data comes in</li>
<li>&quot;Invertible&quot; window aggregations are very efficient</li>
</ul>
<figure>
<img src="images/windows.png" />
</figure>
</section>
<section id="rolling-count-window" class="slide level1">
<h1>Rolling Count Window</h1>
<ul>
<li>As new RDDs enter, they're aggregated and merged into the window</li>
<li>As RDDs exit, the aggregation is applied in reverse</li>
</ul>
<figure>
<img src="images/spark_streaming_window.png" />
</figure>
</section>
<section id="a-better-join" class="slide level1">
<h1>A Better Join</h1>
<ul>
<li><strong>countByValueAndWindow</strong> counts the Ad IDs within the declared window time</li>
<li>Applies the reverse counts as RDDs leave the window</li>
<li>Essentially &quot;sliding batch&quot; solution</li>
</ul>
<figure>
<img src="images/spark_streaming_better.png" />
</figure>
</section>
<section id="considerations" class="slide level1">
<h1>Considerations</h1>
<ul>
<li>Solution relies on <em>processing</em> time - the time events hit the system
<ul>
<li>Data skew and extreme delays could be a problem</li>
<li>High volume bursts could crash the system (not likely though)</li>
</ul></li>
<li>Latency and window accuracy are tightly coupled
<ul>
<li>Shorter microbatch intervals mean the window holds more data</li>
</ul></li>
</ul>
</section>
<section id="storm" class="slide level1">
<h1>Storm</h1>
<ul>
<li>One event at a time</li>
<li>Units of computation are distributed</li>
</ul>
<div class="fragment">
<figure>
<img src="images/ad_storm_topology_simple.png" />
</figure>
</div>
</section>
<section id="joining-with-storm" class="slide level1">
<h1>Joining with Storm</h1>
<figure>
<img src="images/storm_naive_join.png" />
</figure>
<ul>
<li>When an event arrives, emit &quot;impression&quot; and check if user ID is in set</li>
<li>If there is, emit &quot;click&quot;</li>
</ul>
</section>
<section id="joining-with-storm-1" class="slide level1">
<h1>Joining with Storm</h1>
<figure>
<img src="images/storm_naive_join.png" />
</figure>
<ul>
<li>Not robust to out-of-order events, but easily could be</li>
<li>Not memory efficient</li>
</ul>
</section>
<section id="bloom-filters" class="slide level1">
<h1>Bloom Filters</h1>
<ul>
<li>A specialized <strong><em>probabilistic</em></strong> data structure</li>
<li>Returns true <strong><em>every</em></strong> time an element <strong><em>is</em></strong> in the set</li>
<li>Returns true <strong><em>some</em></strong> times an element is <strong><em>not</em></strong> in the set</li>
<li>Space remains constant as elements are added
<ul>
<li>Elements can't be retrieved, but membership can be tested</li>
<li>Eventually &quot;saturate&quot; and become unusable</li>
</ul></li>
</ul>
</section>
<section id="bloom-filter-join" class="slide level1">
<h1>Bloom Filter Join</h1>
<figure>
<img src="images/storm_bloom_join.png" />
</figure>
<ul>
<li><strong><em>Much</em></strong> less memory used</li>
</ul>
</section>
<section id="calculating-clickthrough" class="slide level1">
<h1>Calculating Clickthrough</h1>
<ul>
<li>We need a function <span class="math display">\[f(\text{Ad ID}, \text{[impression | click]}) \rightarrow \text{clickthrough}\]</span></li>
<li>Treat &quot;impression&quot; as zero, &quot;click&quot; as one
<ul>
<li>Simple average doesn't work</li>
<li><span class="math inline">\((0 + 0 + 1) / 3 = 0.33 \neq 0.5\)</span></li>
</ul></li>
</ul>
</section>
<section id="calculating-clickthrough-correctly" class="slide level1">
<h1>Calculating Clickthrough Correctly</h1>
<ul>
<li>avg impressions = <span class="math inline">\(\frac{i}{n}\)</span></li>
<li>avg clicks = <span class="math inline">\(\frac{c}{n}\)</span></li>
<li>clickthrough = <span class="math inline">\(\frac{c}{i} = \frac{c/n}{i/n} = \frac{avg(c)}{avg(i)}\)</span></li>
<li>Averages don't have &quot;memory&quot; - use exponentially weighted moving average
<ul>
<li><span class="math inline">\(\bar{i}_n = \alpha \cdot i + (1 - \alpha) \cdot \bar{i}_o\)</span></li>
</ul></li>
</ul>
</section>
<section id="streaming-clickthrough" class="slide level1">
<h1>Streaming Clickthrough</h1>
<ol type="1">
<li>Two variables: <code>impression</code> and <code>click</code>, set to zero.</li>
<li>When an event arrives, set <code>impression</code> to 1 if it's an impression, set <code>click</code> to 1 if it's a click.</li>
<li>Update the moving averages with <span class="math inline">\(a = \alpha \cdot x + (1 - \alpha) \cdot a\)</span>.</li>
<li>Calculate the clickthrough with the updated averages.</li>
</ol>
</section>
<section id="spark-streaming-vs-storm" class="slide level1">
<h1>Spark Streaming vs Storm</h1>
<ul>
<li>Spark streaming uses microbatches
<ul>
<li>&quot;Exactly once&quot; failover semantics</li>
</ul></li>
<li>Spark's API expresses transformations as operations on collections</li>
<li>Storm processes events one at a time
<ul>
<li>&quot;At least once&quot; failover semantics</li>
</ul></li>
<li>Storm's API expresses transformations as functions</li>
</ul>
</section>
<section id="data-sources" class="slide level1">
<h1>Data Sources</h1>
<ul>
<li>Sensors</li>
<li>Tracking programs</li>
<li>Electronic monitoring</li>
</ul>
<div class="fragment">
<p><strong><em>Data is somewhere else</em></strong></p>
<ul>
<li>No backpressure</li>
<li>No standardization</li>
</ul>
</div>
<div class="fragment">
<p style="border: solid">
Different kind of &quot;stream crossing&quot; - still not recommended.
</p>
</div>
</section>
<section id="section-1" class="slide level1">
<h1><img src="images/kafka_logo.jpg" /></h1>
<ul>
<li>A distributed pub/sub system implemented as an <em>event log</em></li>
<li>Consumers &quot;pull&quot; and track their own offsets
<ul>
<li>Massive scale-out for reads</li>
</ul></li>
</ul>
</section>
<section id="topics" class="slide level1">
<h1>Topics</h1>
<figure>
<img src="images/kafka_topic_anatomy.png" />
</figure>
<ul>
<li>Consumers at early offsets go as fast as they can</li>
<li>Consumers at latest offsets block until new data arrives</li>
</ul>
</section>
<section id="brokers" class="slide level1">
<h1>Brokers</h1>
<figure>
<img src="images/kafka_cluster_anatomy.png" />
</figure>
<ul>
<li>Producers send data to the cluster, which partitions the data within the topic</li>
<li>Consumers read from topics parallelized by the number of partitions for the topic</li>
</ul>
</section>
<section id="streaming-data-platform" class="slide level1">
<h1>Streaming Data Platform</h1>
<figure>
<img src="images/streaming_data_platform.png" />
</figure>
<ul>
<li>Kafka decouples the sources from the consumers</li>
</ul>
</section>
<section id="opinion-time" class="slide level1">
<h1>Opinion Time!</h1>
<p>Kafka is the most critical part of a streaming data architecture.</p>
</section>
<section class="slide level1">

<ul>
<li>Even trivial problems need to be carefully handled when converted to streaming</li>
<li>Windowing with Spark Streaming is basically batch</li>
<li>Storm requires more work, but is more robust</li>
<li>Kafka decouples the sources from the processors
<ul>
<li>Great data resiliency</li>
<li>Natural backpressure mechanism</li>
</ul></li>
</ul>
</section>
<section id="really-really-new-stuff" class="slide level1">
<h1>Really Really New Stuff</h1>
<ul>
<li>Apache Beam - Google's Cloud Dataflow SDK
<ul>
<li>Works with <em>event time</em>, with very strong consistency semantics</li>
<li>Runs on Flink (streaming) or Spark (batch)</li>
</ul></li>
<li>Apache Flink event-based with collection-oriented API
<ul>
<li>Provides strong consistency guarantees without microbatching as well as event-time processing</li>
</ul></li>
<li>Kafka will be adding a processor API with tight writeback integration</li>
<li>Storm recently added windowing and managed state</li>
</ul>
</section>
<section id="thanks" class="slide level1">
<h1>Thanks</h1>
<ul>
<li>Mike and Dustun / Actian for hosting</li>
<li>Chance, Rob, and Omar for running the meetup</li>
<li>Raj Kalluri, Chris Gerken (Intersys)</li>
</ul>
</section>
<section id="references" class="slide level1">
<h1>References</h1>
<ul>
<li><strong>Code:</strong> <a href="https://github.com/timothyrenner/clickthrough-stream-example">github.com/timothyrenner/clickthrough-stream-example</a></li>
<li><strong>Slides:</strong> <a href="http://timothyrenner.github.io/talks">timothyrenner.github.io/talks</a></li>
<li><strong>Spark Streaming:</strong> <a href="http://spark.apache.org">spark.apache.org</a>, <a href="http://databricks.com">databricks.com</a></li>
<li><strong>Storm:</strong> <a href="http://storm.apache.org">storm.apache.org</a></li>
<li><strong>Kafka:</strong> <a href="http://kafka.apache.org">kafka.apache.org</a>, <a href="http://confluent.io">confluent.io</a></li>
</ul>
</section>
<section id="homework" class="slide level1">
<h1>Homework!</h1>
<h4 id="how-can-kafka-be-used-as-an-architectural-component-to-simplify-the-spark-streaming-storm-solutions">How can Kafka be used as an architectural component to simplify the Spark Streaming / Storm solutions?</h4>
</section>
    </div>
  </div>

  <script src="../reveal.js/lib/js/head.min.js"></script>
  <script src="../reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({

        // Optional reveal.js plugins
        dependencies: [
          { src: '../reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: '../reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: '../reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
